#!/usr/bin/env python3

"""
Program module providing the progam class with cycle breaking methods and clark completion(s).
"""

import networkx as nx
import os
import logging
import numpy as np


from aspmc.parsing.clingoparser.clingoext import ClingoRule

from aspmc.graph.hypergraph import Hypergraph
import aspmc.graph.treedecomposition as treedecomposition

from aspmc.compile.cnf import CNF

from aspmc.parsing.clingoparser.clingoext import Control
import aspmc.programs.backdoor as backdoor
import aspmc.programs.grounder as grounder

import aspmc.config as config

from aspmc.programs.naming import *

logger = logging.getLogger("aspmc")

class UnsupportedException(Exception):
    '''raise this when the program relies on features that are not supported yet'''

class Rule(object):
    """A class for rules.

    Implements a custom `__repr__` method.

    Args:        
        head (:obj:`list`): The list of head atoms as dimacs literals. May be empty.
        body (:obj:`list`): The list of body atoms as dimacs literals. May be empty.

    Attributes:
        head (:obj:`list`): The list of head atoms as dimacs literals. May be empty.
        body (:obj:`list`): The list of body atoms as dimacs literals. May be empty.
    """
    def __init__(self, head, body):
        self.head = head
        self.body = body

    def __repr__(self):
        return "; ".join([str(a) for a in self.head]) + ":- " + ", ".join([ ("not " if b < 0 else "") + str(abs(b)) for b in self.body]) 

class Program(object):
    """A base class for programs. No weights, no queries this is only for getting a cnf representation of the program.

    Allowed features are: 

    * facts
    * normal rules
    * unconditional choice constraints
    * constraints

    The cnf is generated by first doing Tp-Unfolding and then applying a Clark completion to the resulting tight program. 

    Args:
        program_str (:obj:`string`): A string containing a part of the program in ASP syntax. 
            May be the empty string.
        program_files (:obj:`list`): A list of string that are paths to files which contain programs in ASP syntax 
            that should be included. May be an empty list.
        clingo_control (:obj:`Control`): A clingo control object that contains parts of the program. 
            Must already be ground if no non-empty `program_str` or `program_files` are given.
    """
    def __init__(self, clingo_control = Control(), program_str = "", program_files = []):
        if len(program_str) > 0 or len(program_files) > 0:
            grounder.ground(clingo_control, program_str = program_str, program_files = program_files)
        # the variable counter
        self._max = 0
        self._nameMap = {}
        # store the clauses here
        self._cnf = CNF()
        # remember which variables are guesses, which are derived, and which are copies of derived atoms.
        self._guess = set()
        self._deriv = set()
        self._copies = {}
        # the list containing all the rules (except guesses)
        self._program = []
        # the tree decomposition of the program
        self._td = None
        self._normalize(clingo_control)

    def _remove_tautologies(self, clingo_control):
        tmp = []
        for o in clingo_control.ground_program.objects:
            if isinstance(o, ClingoRule) and set(o.head).intersection(set(o.body)) == set():
                tmp.append(o)
        return tmp

    def _normalize(self, clingo_control):
        program = self._remove_tautologies(clingo_control)
        _atomToVertex = {} # htd wants succinct numbering of vertices / no holes
        _vertexToAtom = {} # inverse mapping of _atomToVertex 

        symbol_map = {}
        for sym in clingo_control.symbolic_atoms:
            symbol_map[sym.literal] = str(sym.symbol)
        for o in program:
            if isinstance(o, ClingoRule):
                if len(o.head) > 1:
                    raise UnsupportedException("Currently only rules with at most one atom in the head are supported.")
                o.atoms = set(o.head)
                o.atoms.update(tuple(map(abs, o.body)))
                # if we have the falsum rule we want to replace it with two rules
                if not o.atoms:
                    a = self._new_var("unsat")
                    _atomToVertex[a] = a
                    _vertexToAtom[a] = a
                    o.atoms.add(a)
                    o.head = [a]
                    o.body = [-a]
                self._program.append(o)
                for a in o.atoms.difference(_atomToVertex):	# add mapping for atom not yet mapped
                    if a in symbol_map:
                        _atomToVertex[a] = self._new_var(symbol_map[a])
                    else:
                        _atomToVertex[a] = self._new_var(f"projected_away({a})")
                    _vertexToAtom[self._max] = a

        trans_prog = set()
        for r in self._program:
            if r.choice: 
                self._guess.add(_atomToVertex[r.head[0]])
            else:
                head = list(map(lambda x: _atomToVertex[x], r.head))
                body = list(map(lambda x: _atomToVertex[abs(x)]*(1 if x > 0 else -1), r.body))
                trans_prog.add(Rule(head,body))
        self._program = trans_prog
        self._deriv = set(range(1,self._max + 1)).difference(self._guess)

    def _new_var(self, name):
        self._max += 1
        self._nameMap[self._max] = name if name != "" else str(self._max)
        return self._max

    def _copy_var(self, var):
        if "(" in self._nameMap[var]:
            idx = self._nameMap[var].index("(")
            inputs = self._nameMap[var][idx:]
        else:
            inputs = ""
        if "_copy_" in self._nameMap[var]:
            idx = self._nameMap[var].index("_copy_")
            pred = self._nameMap[var][:idx]
        else:
            pred = self._nameMap[var]
            if "(" in pred:
                idx = pred.index("(")
                pred = pred[:idx]
            if pred+inputs not in self._copies:
                self._copies[pred+inputs] = [var]
        cnt = len(self._copies[pred+inputs])
        name = pred + "_copy_" + str(cnt) + inputs
        nv = self._new_var(name)
        self._copies[pred+inputs].append(nv)
        return nv

    def _internal_name(self, var):
        return self._nameMap[var]
    
    def _external_name(self, var):
        name = self._nameMap[var]
        # replace internal names with external names so we can parse programs that we print without errors
        for (internal, external) in conversions.items():
            name = name.replace(internal, external)
        return name

    def _computeComponents(self):
        self.dep = nx.DiGraph()
        self.dep.add_nodes_from(range(1, self._max + 1))
        for r in self._program:
            for a in r.head:
                for b in r.body:
                    if b > 0:
                        self.dep.add_edge(b, a)
        comp = nx.algorithms.strongly_connected_components(self.dep)
        self._components = list(comp)
        self._condensation = nx.algorithms.condensation(self.dep, self._components)
        """
        import matplotlib.pyplot as plt
        from networkx.drawing.nx_pydot import graphviz_layout
        labels = { node : str(node) for node in range(1, self._max + 1) }
        node_to_comp = {}
        for comp in self._components:
            for v in comp:
                node_to_comp[v] = comp
        red_edges = [ (v,u) for v,u in self.dep.edges() if node_to_comp[v] == node_to_comp[u] ]
        edge_colours = ['black' if not edge in red_edges else 'red' for edge in self.dep.edges()]
        black_edges = [ (v,u) for v,u in self.dep.edges() if node_to_comp[v] != node_to_comp[u] ]
        pos = graphviz_layout(self.dep, prog="dot")
        nx.draw(self.dep, pos)
        nx.draw_networkx_labels(self.dep, pos, labels)
        nx.draw_networkx_edges(self.dep, pos, edgelist=red_edges, edge_color='r', arrows=True)
        nx.draw_networkx_edges(self.dep, pos, edgelist=black_edges, arrows=True)
        plt.axis("off")
        plt.show()
        """

    def treeprocess(self):
        """Applies tree processing to the program. 
        
        This means that if there is a part of the dependency graph that is a tree and
        only has one connection to the rest of the dependency graph, then it will be processed.

        Results in one copy for each atom in the tree.

        Returns:
            None        
        """
        ins = {}
        outs = {}
        for a in self._deriv.union(self._guess):
            ins[a] = set()
            outs[a] = set()
        for r in self._program:
            for a in r.head:
                ins[a].add(r)
            for b in r.body:
                if b > 0:
                    outs[b].add(r)
        ts = nx.topological_sort(self._condensation)
        ancs = {}
        decs = {}
        for t in ts:
            comp = self._condensation.nodes[t]["members"]
            for v in comp:
                ancs[v] = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
                decs[v] = set([vp[1] for vp in self.dep.out_edges(nbunch=v) if vp[1] in comp])
        q = set([v for v in ancs.keys() if len(ancs[v]) == 1 and len(decs[v]) == 1 and list(ancs[v])[0] == list(decs[v])[0]])
        while not len(q) == 0:
            old_v = q.pop()
            if len(ancs[old_v]) == 0:
                continue
            new_v = self._copy_var(old_v)
            self._deriv.add(new_v)
            ins[new_v] = set()
            outs[new_v] = set()
            anc = ancs[old_v].pop()
            ancs[anc].remove(old_v)
            decs[anc].remove(old_v)
            if len(ancs[anc]) == 1 and len(decs[anc]) == 1 and list(ancs[anc])[0] == list(decs[anc])[0]:
                q.add(anc)

            # this contains all rules that do not use anc to derive v
            to_rem = ins[old_v].difference(outs[anc])
            # this contains all rules that use anc to derive v
            # we just keep them as they are
            ins[old_v] = ins[old_v].intersection(outs[anc])
            # any rule that does not use anc to derive v can now only derive new_v
            for r in to_rem:
                head = [b if b != old_v else new_v for b in r.head]
                new_r = Rule(head,r.body)
                ins[new_v].add(new_r)
                for b in r.body:
                    if b > 0:
                        outs[b].remove(r)
                        outs[b].add(new_r)

            # this contains all rules that use v and derive anc
            to_rem = outs[old_v].intersection(ins[anc])
            # this contains all rules that use v and do not derive anc
            # we just keep them as they are
            outs[old_v] = outs[old_v].difference(ins[anc])
            # any rule that uses v to derive anc must use new_v
            for r in to_rem:
                body = [ (b if b != old_v else new_v) for b in r.body]
                new_r = Rule(r.head,body)
                for b in r.head:
                    ins[b].remove(r)
                    ins[b].add(new_r)
                for b in r.body:
                    if b > 0:
                        if b != old_v:
                            outs[abs(b)].remove(r)
                            outs[abs(b)].add(new_r)
                        else:
                            outs[new_v].add(new_r)
            new_r = Rule([old_v], [new_v])
            ins[old_v].add(new_r)
            outs[new_v].add(new_r)
        # only keep the constraints
        self._program = [r for r in self._program if len(r.head) == 0]
        # add all the other rules
        for a in ins.keys():
            self._program.extend(ins[a])


    def _write_scc(self, comp):
        res = ""
        for v in comp:
            res += f"p({v}).\n"
            ancs = set([vp[0] for vp in self.dep.in_edges(nbunch=v) if vp[0] in comp])
            for vp in ancs:
                res += f"edge({vp},{v}).\n"
        return res

    def _compute_backdoor(self, idx):
        comp = self._condensation.nodes[idx]["members"]
        local_dep = self.dep.subgraph(comp)
        try:
            if len(comp) > 100:
                basis = nx.cycle_basis(local_dep.to_undirected())
                res = []
                while len(basis) > 0:
                    prog = f"b({len(comp)//2}).\n" + "\n".join([f"p({v})." for v in comp if v not in res]) + "\n"
                    for c in basis:
                        prog += ":-" + ", ".join([f"not abs({v})" for v in c]) + ".\n"
                    c = backdoor.ClingoControl(prog)
                    res += c.get_backdoor(os.path.dirname(os.path.abspath(__file__)) + "/guess_backdoor.lp")[2][0]
                    local_dep = self.dep.subgraph([x for x in comp if x not in res])
                    basis = nx.cycle_basis(local_dep.to_undirected())
            else:
                try:
                    c = backdoor.ClingoControl(f"b({len(comp)//2}).\n" + self._write_scc(comp))
                    res = c.get_backdoor(os.path.dirname(os.path.abspath(__file__)) + "/guess_tree.lp")[2][0]
                except:
                    basis = nx.cycle_basis(local_dep.to_undirected())
                    res = []
                    while len(basis) > 0:
                        prog = "\n".join([f"p({v})." for v in comp if v not in res]) + "\n"
                        for c in basis:
                            prog += ":-" + ", ".join([f"not abs({v})" for v in c]) + ".\n"
                        c = backdoor.ClingoControl(prog)
                        res += c.get_backdoor(os.path.dirname(os.path.abspath(__file__)) + "/guess_backdoor.lp")[2][0]
                        local_dep = self.dep.subgraph([x for x in comp if x not in res])
                        basis = nx.cycle_basis(local_dep.to_undirected())
        except:
            res = comp
            logger.error("backdoor guessing failed, returning whole component.")
        logger.debug("backdoor comp: " + str(len(comp)))
        logger.debug("backdoor res: " + str(len(res)))
        return res

    def _backdoor_process(self, comp, backdoor):
        comp = set(comp)
        backdoor = set(backdoor)

        toRemove = set()
        ins = {}
        for a in comp:
            ins[a] = set()
        for r in self._program:
            for a in r.head:
                if a in comp:
                    ins[a].add(r)
                    toRemove.add(r)

        copies = {}
        for a in comp:
            copies[a] = {}
            copies[a][len(backdoor)] = a

        def getAtom(atom, i):
            # negated atoms are kept as they are
            if atom < 0:
                return atom
            # atoms that are not from this component are input atoms and should stay the same
            if atom not in comp:
                return atom
            if i < 0:
                print("this should not happen")
                exit(-1)
            if atom not in copies:
                print("this should not happen")
                exit(-1)
            if i not in copies[atom]:
                copies[atom][i] = self._copy_var(atom)
                self._deriv.add(copies[atom][i])
            return copies[atom][i]

        toAdd = set()
        for a in backdoor:
            for i in range(1,len(backdoor)+1):
                head = [getAtom(a, i)]
                for r in ins[a]:
                    if i == 1:
                        # in the first iteration we do not add rules that use atoms from the backdoor
                        add = True
                        for x in r.body:
                            if x > 0 and x in backdoor:
                                add = False
                    else:
                        # in all but the first iteration we only use rules that use at least one atom from the SCC we are in
                        add = False
                        for x in r.body:
                            if x > 0 and x in comp:
                                add = True
                    if add:
                        body = [getAtom(x, i - 1) for x in r.body]
                        new_rule = Rule(head, body)
                        toAdd.add(new_rule)
                if i > 1:
                    toAdd.add(Rule(head, [getAtom(a, i - 1)]))

        for a in comp.difference(backdoor):
            for i in range(len(backdoor)+1):
                head = [getAtom(a, i)]
                for r in ins[a]:
                    if i == 0:
                        # in the first iteration we only add rules that only use atoms from outside 
                        add = True
                        for x in r.body:
                            if x > 0 and x in backdoor:
                                add = False
                    else:
                        # in all other iterations we only use rules that use at least one atom from the SCC we are in
                        add = False
                        for x in r.body:
                            if x >  0 and x in comp:
                                add = True
                    if add:
                        body = [getAtom(x, i) for x in r.body]
                        new_rule = Rule(head, body)
                        toAdd.add(new_rule)
                if i > 0:
                    toAdd.add(Rule(head, [getAtom(a, i - 1)]))

        self._program = [r for r in self._program if r not in toRemove]
        self._program += list(toAdd)
        
        
    def tpUnfold(self):
        """Applies Tp-Unfolding to the program. 
        
        Applies a variant to be precise by first doing treeprocessing
        and then Tp-Unfolding as this can be a bit better.

        Returns:
            None        
        """
        self._computeComponents()
        self.treeprocess()
        self._computeComponents()
        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t]["members"]
            if len(comp) > 1:
                self._backdoor_process(comp, self._compute_backdoor(t))
        self._computeComponents()
        self.treeprocess()
        self._computeComponents()
        ts = nx.topological_sort(self._condensation)
        for t in ts:
            comp = self._condensation.nodes[t]["members"]
            if len(comp) > 1:
                logger.error("Cycle breaking failed: the dependency graph still has a non-trivial SCC")
                exit(-1)

    def _decomposeGraph(self, solver = "htd", timeout = "0.5"):            
        self._graph = Hypergraph()
        self._graph.add_nodes_from(range(1, self._max + 1))
        for r in self._program:
            atoms = set(r.head)
            atoms.update(tuple(map(abs, r.body)))
            self._graph.add_edge(atoms)
        self._td = treedecomposition.from_hypergraph(self._graph, solver = solver, timeout = timeout)
        logger.info(f"Tree Decomposition #bags: {self._td.bags} treewidth: {self._td.width} #vertices: {self._td.vertices}")

    def clark_completion(self):
        """Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Does not use tree decomposition guidance to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        Returns:
            None        
        """
        perAtom = {}
        for a in self._deriv:
            perAtom[a] = []

        for r in self._program:
            for a in r.head:
                perAtom[a].append(r)

        for head in self._deriv:
            ors = []
            for r in perAtom[head]:
                ors.append(self._new_var(f"{r}"))
                ands = [-x for x in r.body]
                self._cnf.clauses.append([ors[-1]] + ands)
                for at in ands:
                    self._cnf.clauses.append([-ors[-1], -at])
            self._cnf.clauses.append([-head] + [o for o in ors])
            for o in ors:
                self._cnf.clauses.append([head, -o])

        constraints = [r for r in self._program if len(r.head) == 0]
        for r in constraints:
            self._cnf.clauses.append([-x for x in r.body])
        self._cnf.nr_vars = self._max
        self._finalize_cnf()

    def td_guided_clark_completion(self):        
        """Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Use tree decomposition guidance on the "ors" to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None        
        """
        self._decomposeGraph(solver = config.config["decos"], timeout = config.config["decot"])

        # at which td node to handle each rule
        rules = {}
        # at which td node each variable occurs last
        last = {}
        idx = 0
        td_idx = list(self._td)
        for t in self._td.bag_iter():
            for a in t.vertices:
                last[a] = idx
            t.idx = idx
            idx += 1
            rules[t] = []

        for r in self._program:
            for a in r.head:
                r.proven = self._new_var(f"{r}")
                ands = [-x for x in r.body]
                self._cnf.clauses.append([ r.proven ] + ands)
                for at in ands:
                    self._cnf.clauses.append([ -r.proven, -at ])
            idx = min([ last[abs(b)] for b in r.body + r.head ])
            rules[self._td.get_bag(td_idx[idx])].append(r)

        # how many rules have we used and what is the last used variable
        unfinished = {}
        for t in self._td.bag_iter():
            unfinished[t] = {}
            t.vertices = set(t.vertices)
            to_handle = {}
            for a in t.vertices:
                to_handle[a] = []
            for tp in t.children:
                removed = tp.vertices.difference(t.vertices)
                for a in removed:
                    if a in self._deriv:
                        if a in unfinished[tp]:
                            final = unfinished[tp].pop(a)
                            self._cnf.clauses.append([-a, final])
                            self._cnf.clauses.append([a, -final])
                        else: 
                            self._cnf.clauses.append([-a])
                rest = tp.vertices.intersection(t.vertices)
                for a in rest:
                    if a in unfinished[tp]:
                        to_handle[a].append(unfinished[tp][a])

            # take the rules we need
            for r in rules[t]:
                for a in r.head:
                    to_handle[a].append(r.proven)

            # handle all the rules we have gathered
            for a in t.vertices:
                if len(to_handle[a]) > 1:
                    new_last = self._new_var("{t},{a}")
                    self._cnf.clauses.append([-new_last] + to_handle[a])
                    for at in to_handle[a]:
                        self._cnf.clauses.append([new_last, -at])
                    unfinished[t][a] = new_last
                elif len(to_handle[a]) == 1:
                    unfinished[t][a] = to_handle[a][0]

        for a in self._td.get_root().vertices:
            if a in self._deriv:
                if a in unfinished[self._td.get_root()]:
                    final = unfinished[self._td.get_root()].pop(a)
                    self._cnf.clauses.append([-a, final])
                    self._cnf.clauses.append([a, -final])
                else: 
                    self._cnf.clauses.append([-a])

        constraints = [r for r in self._program if len(r.head) == 0]
        for r in constraints:
            self._cnf.clauses.append([-x for x in r.body])
        self._cnf.nr_vars = self._max
        self._finalize_cnf()


    def td_guided_both_clark_completion(self):        
        """Applies the clark completion to the program. 

        Does not check whether the program is tight! 
        Use tree decomposition guidance on both the "ands" and the "ors"
        to obtain a program of possibly smaller treewidth.
        
        Does not return anything only constructs the cnf.
        The CNF can be obtained by using `get_cnf()`.

        The solver to compute the tree decomposition and its timeout can be specified in 
        aspmc.config.

        Returns:
            None        
        """
        # remember whats an and, whats an or and whats a constraint
        # also include their inputs
        OR = 0
        AND = 1
        CON = 2
        INPUT = 3
        nodes = { a : (OR, set()) for a in self._deriv }
        for a in self._guess:
            nodes[a] = (INPUT, None)

        for r in self._program:
            if len(r.body) == 0: # special case for facts
                self._cnf.clauses.append([r.head[0]])
                continue
            r.proven = self._new_var(f"{r}")
            if len(r.head) != 0:
                nodes[r.proven] = (AND, set(r.body))
                nodes[abs(r.head[0])][1].add(r.proven)
            else:
                nodes[r.proven] = (CON, set([ -atom for atom in r.body ]))

        # set up the and/or graph
        graph = nx.Graph()
        graph.add_nodes_from(range(1, self._max + 1))
        for r in self._program:
            if len(r.body) > 0:
                for atom in r.head:
                    graph.add_edge(r.proven, atom)
                for atom in r.body:
                    graph.add_edge(r.proven, abs(atom))


        td = treedecomposition.from_graph(graph, solver = config.config["decos"], timeout = config.config["decot"])
        logger.info(f"Tree Decomposition #bags: {td.bags} treewidth: {td.width} #vertices: {td.vertices}")
        

        # remember per bag which nodes have which partial result
        unfinished = {}
        # handle the bags in dfs order
        for t in td.bag_iter():
            unfinished[t] = {}
            # first take care of what we got from the children
            for tp in t.children:
                for atom in unfinished[tp]:
                    if atom not in unfinished[t]:
                        unfinished[t][atom] = unfinished[tp][atom]
                    else:
                        if len(unfinished[tp][atom]) == 1:
                            first_lit = unfinished[tp][atom].pop()
                        else:
                            node_type = nodes[atom][0]
                            first_lit = self._new_var("")
                            if node_type == AND:
                                bigAnd = [ first_lit ] + [ -v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigAnd)                  
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ -first_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -first_lit ] + [ v for v in unfinished[tp][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[tp][atom]:
                                    self._cnf.clauses.append([ first_lit, -v ])

                        if len(unfinished[t][atom]) == 1:
                            second_lit = unfinished[t][atom].pop()
                        else:
                            node_type = nodes[atom][0]
                            second_lit = self._new_var("")
                            if node_type == AND:
                                bigAnd = [ second_lit ] + [ -v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigAnd)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ -second_lit, v ])
                            elif node_type == OR or node_type == CON:
                                bigOr = [ -second_lit ] + [ v for v in unfinished[t][atom] ]
                                self._cnf.clauses.append(bigOr)
                                for v in unfinished[t][atom]:
                                    self._cnf.clauses.append([ second_lit, -v ])

                        unfinished[t][atom] = set([first_lit, second_lit])
                        
            # then take care of the current bag
            for a in t.vertices:
                node_type, inputs = nodes[a]
                if node_type == INPUT:
                    continue
                todo_new = set([ atom for atom in inputs if abs(atom) in t.vertices ])
                if len(todo_new) == 0:
                    continue
                inputs.difference_update(todo_new)
                if a not in unfinished[t]:
                    unfinished[t][a] = todo_new
                else:
                    if len(unfinished[t][a]) == 1:
                        first_lit = unfinished[t][a].pop()
                    else:
                        first_lit = self._new_var("")
                        if node_type == AND:
                            bigAnd = [ first_lit ] + [ -v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigAnd)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ -first_lit, v ])
                        elif node_type == OR or node_type == CON:
                            bigOr = [ -first_lit ] + [ v for v in unfinished[t][a] ]
                            self._cnf.clauses.append(bigOr)
                            for v in unfinished[t][a]:
                                self._cnf.clauses.append([ first_lit, -v ])

                    if len(todo_new) == 1:
                        second_lit = todo_new.pop()
                    else:
                        second_lit = self._new_var("")
                        if node_type == AND:
                            bigAnd = [ second_lit ] + [ -v for v in todo_new ]
                            self._cnf.clauses.append(bigAnd)
                            for v in todo_new:
                                self._cnf.clauses.append([ -second_lit, v ])
                        elif node_type == OR or node_type == CON:
                            bigOr = [ -second_lit ] + [ v for v in todo_new ]
                            self._cnf.clauses.append(bigOr)
                            for v in todo_new:
                                self._cnf.clauses.append([ second_lit, -v ])

                    unfinished[t][a] = set([first_lit, second_lit])

            # check which nodes are completely done and finalize them
            new_unfinished = {}
            for a in unfinished[t]:
                if a in t.vertices: # if the variable is still there, we keep it
                    new_unfinished[a] = unfinished[t][a]
                else: # otherwise we finalize the node
                    node_type = nodes[a][0]
                    if node_type == AND:
                        bigAnd = [ a ] + [ -v for v in unfinished[t][a] ]
                        self._cnf.clauses.append(bigAnd)
                        for v in unfinished[t][a]:
                            self._cnf.clauses.append([ -a, v ])
                    elif node_type == OR:
                        bigOr = [ -a ] + [ v for v in unfinished[t][a] ]
                        self._cnf.clauses.append(bigOr)
                        for v in unfinished[t][a]:
                            self._cnf.clauses.append([ a, -v ])
                    elif node_type == CON:
                        bigOr = [ v for v in unfinished[t][a] ]
                        self._cnf.clauses.append(bigOr)
                        self._cnf.clauses.append([-a])

            unfinished[t] = new_unfinished

        # finalize the nodes that are left in the root
        root = td.get_root()
        for a in unfinished[root]:
            node_type = nodes[a][0]
            if node_type == AND:
                bigAnd = [ a ] + [ -v for v in unfinished[root][a] ]
                self._cnf.clauses.append(bigAnd)
                for v in unfinished[root][a]:
                    self._cnf.clauses.append([ -a, v ])
            elif node_type == OR:
                bigOr = [ -a ] + [ v for v in unfinished[root][a] ]
                self._cnf.clauses.append(bigOr)
                for v in unfinished[root][a]:
                    self._cnf.clauses.append([ a, -v ])
            elif node_type == CON:
                bigOr = [ v for v in unfinished[root][a] ]
                self._cnf.clauses.append(bigOr)
                self._cnf.clauses.append([-a])
        self._cnf.nr_vars = self._max
        self._finalize_cnf()

    def _finalize_cnf(self):
        pass

    def encoding_stats(self):
        """Print the stats of a tree decomposition of the cnf computed with "htd". 

        Returns:
            None        
        """
        primal = Hypergraph()
        primal.add_nodes_from(range(1, self._max + 1))
        primal.add_edges_from([ set([ abs(x) for x in c ]) for c in self._cnf.clauses ])
        td = treedecomposition.from_hypergraph(primal)
        logger.info(f"Tree Decomposition #bags: {td.bags} treewidth: {td.width} #vertices: {td.vertices}")      

    def get_cnf(self):
        """Used to get the extended cnf corresponding to the program. 

        Only possible after having called `tpUnfold()` and one of the Clark completion methods.
        
        Returns:
            :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
        """
        return self._cnf

    def write_dimacs(self, stream, **kwargs):
        """Write the extended cnf corresponding to the program to a stream. 

        Only possible after having called `tpUnfold()` and one of the Clark completion methods.
        
        Args:
            stream (:obj:`stream`): The stream to write to. Must be binary.

        Returns:
            :obj:`aspmc.compile.cnf.CNF`: Returns the extended cnf of the program.        
        """
        if "debug" in kwargs:
            for c in self._cnf.clauses:
                stream.write(f"p cnf {self._max} {len(self._cnf.clauses)}\n".encode())
                stream.write((" ".join([("not " if v < 0 else "") + self._external_name(abs(v)) for v in c]) + " 0\n" ).encode())
        else:
            self._cnf.to_stream(stream)


    def _prog_string(self, program):
        """Get a string representation of a part of the program. 

        Should be overwritten by subclasses.

        Args:
            program (:obj:`list`): List of rules that should be printed.

        Returns:
            :obj:`string`: A string representation of the rules in `program`.        
        """
        result = ""
        for v in self._guess:
            result += f"{{{self._external_name(v)}}}.\n"
        for r in program:
            result += ";".join([ self._external_name(v) for v in r.head ])
            if len(r.body) > 0:
                result += ":-"
                result += ",".join([("not " if v < 0 else "") + self._external_name(abs(v)) for v in r.body])
            result += ".\n"
        return result

    def write_prog(self, stream, spanning = False):
        """Write the (spanning) program to a stream.

        Args:
            stream (:obj:`stream`): The stream to write to. Must be binary.
            spanning (:obj:`bool`, optional): Whether the to write (case `False`) the actual program,
                possibly with weights and utilities and such or (case `True`) only the spanning program. 
                The spanning program corresponds to the underlying propositional theory.
                Defaults to `False`.

        Returns:
            None     
        """
        if spanning:
            stream.write(Program._prog_string(self, self._program).encode())
        else:
            stream.write(self._prog_string(self._program).encode())

    def get_weights(self):
        """Get the weights of all the literals. 

        Should be overwritten by subclasses.

        Returns:
            :obj:`list`: A list of `weights` as numpy arrays.      
                The weight of literal `v` is in `weights[2*(v-1)]`, the one for `-v` is in `weights[2*(v-1)+1]`
        """
        return [ np.array([1.0]) for _ in range(self._max*2) ]

    def get_queries(self):
        """Get the queries (names not literals). 

        Should be overwritten by subclasses.

        Returns:
            :obj:`list`: A list of queries. 
                The empty list corresponds to asking for the overall weight of the program.
        """
        return []

